{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "5G3d7A7CUfF_"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WeHsgGH3WMCl"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "N2M0FTeiWSIl"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2_U5nPDgKu57"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ga8OfZ6nBtyV"
   },
   "outputs": [],
   "source": [
    "del(model)\n",
    "del(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ScdUdyL5LGfx"
   },
   "outputs": [],
   "source": [
    "model = VGG19(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Mvo3So0VLrgP"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "z7cTNJtmLtjv"
   },
   "outputs": [],
   "source": [
    "x = model.output\n",
    "predictions = Dense(7, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1525355100253,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "EO6EHo_FLu-v",
    "outputId": "e6d1960e-cec8-42a2-9b8a-6d947d715307"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_final = Model(input=model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LGzcFatNL55i"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IKY2lrn_LQRB"
   },
   "outputs": [],
   "source": [
    "model_final.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353344,
     "status": "ok",
     "timestamp": 1525355458734,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "f5lbYJ_0LSgO",
    "outputId": "dea2a362-6489-4c60-fadf-15bda5faee4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29068 samples, validate on 3230 samples\n",
      "Epoch 1/10\n",
      "29068/29068 [==============================] - 36s 1ms/step - loss: 1.7122 - acc: 0.3103 - val_loss: 1.6728 - val_acc: 0.3263\n",
      "Epoch 2/10\n",
      " 7776/29068 [=======>......................] - ETA: 23s - loss: 1.6566 - acc: 0.333529068/29068 [==============================] - 35s 1ms/step - loss: 1.6454 - acc: 0.3454 - val_loss: 1.6347 - val_acc: 0.3477\n",
      "Epoch 3/10\n",
      "20832/29068 [====================>.........] - ETA: 9s - loss: 1.6243 - acc: 0.355629068/29068 [==============================] - 35s 1ms/step - loss: 1.6244 - acc: 0.3560 - val_loss: 1.6151 - val_acc: 0.3539\n",
      "Epoch 4/10\n",
      "25760/29068 [=========================>....] - ETA: 3s - loss: 1.6116 - acc: 0.366829068/29068 [==============================] - 35s 1ms/step - loss: 1.6125 - acc: 0.3658 - val_loss: 1.6066 - val_acc: 0.3588\n",
      "Epoch 5/10\n",
      "27616/29068 [===========================>..] - ETA: 1s - loss: 1.6028 - acc: 0.368329068/29068 [==============================] - 35s 1ms/step - loss: 1.6030 - acc: 0.3685 - val_loss: 1.6010 - val_acc: 0.3703\n",
      "Epoch 6/10\n",
      "28320/29068 [============================>.] - ETA: 0s - loss: 1.5957 - acc: 0.371729068/29068 [==============================] - 35s 1ms/step - loss: 1.5953 - acc: 0.3723 - val_loss: 1.5892 - val_acc: 0.3752\n",
      "Epoch 7/10\n",
      "28640/29068 [============================>.] - ETA: 0s - loss: 1.5904 - acc: 0.374729068/29068 [==============================] - 35s 1ms/step - loss: 1.5900 - acc: 0.3751 - val_loss: 1.5964 - val_acc: 0.3672\n",
      "Epoch 8/10\n",
      "28640/29068 [============================>.] - ETA: 0s - loss: 1.5842 - acc: 0.380429068/29068 [==============================] - 35s 1ms/step - loss: 1.5839 - acc: 0.3808 - val_loss: 1.5845 - val_acc: 0.3774\n",
      "Epoch 9/10\n",
      "28640/29068 [============================>.] - ETA: 0s - loss: 1.5800 - acc: 0.380729068/29068 [==============================] - 35s 1ms/step - loss: 1.5794 - acc: 0.3805 - val_loss: 1.5865 - val_acc: 0.3656\n",
      "Epoch 10/10\n",
      "28576/29068 [============================>.] - ETA: 0s - loss: 1.5766 - acc: 0.380829068/29068 [==============================] - 35s 1ms/step - loss: 1.5767 - acc: 0.3808 - val_loss: 1.5842 - val_acc: 0.3842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfb3653908>"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit(np.array(X_train), np.array(y_train),\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "error",
     "timestamp": 1525355899528,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "8fqZKuGS2MF-",
    "outputId": "5ac6a06f-5734-4dda-96b6-0de5ff4438c7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-773f586bb28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_final' is not defined"
     ]
    }
   ],
   "source": [
    "for layer in model_final.layers[7:]:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m-sfYzK226da"
   },
   "outputs": [],
   "source": [
    "model_final.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fX_e2red7Ahd"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator.fit(np.array(X_train))\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True)\n",
    "\n",
    "test_generator.fit(np.array(X_train))\n",
    "\n",
    "model_final.fit_generator(train_generator.flow(np.array(X_train), np.array(y_train), batch_size=32),\n",
    "                          steps_per_epoch=len(X_train)/32, \n",
    "                          epochs=50, \n",
    "                          validation_data=test_generator.flow(np.array(X_test), np.array(y_test), batch_size=32),\n",
    "                          callbacks=[lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3695,
     "status": "ok",
     "timestamp": 1525344589039,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "0cl80j91LeKX",
    "outputId": "aa46fe8f-5ecd-4ba7-844a-04defab4db2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 3s 885us/step\n",
      "Loss: 0.9704667871361756\n",
      "Accuracy: 0.6804123711506282\n"
     ]
    }
   ],
   "source": [
    "scores = model_final.evaluate(np.array(X_test), np.array(y_test), batch_size=batch_size)\n",
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RedmyZ8iLfFG"
   },
   "outputs": [],
   "source": [
    "model.save('./drive/Emotion Recognition/models/model_v7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2492,
     "status": "ok",
     "timestamp": 1525344769413,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "BVGCf8iyoOpp",
    "outputId": "a920ae58-7216-4738-8671-ddffa4fed19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab  drive\tmodel_v6.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H02u-a-1Ha3_"
   },
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JDit6z0EWTA3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "MODELPATH = 'drive/Emotion Recognition/models/model_v5.h5'\n",
    "\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jMiGazmgKOK7"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'drive/Emotion Recognition/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ggQ_ciwBWf9R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('drive/Emotion Recognition/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1525331116474,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "DTkkitUFW1Rr",
    "outputId": "2c23e663-a148-4fd6-ad4e-297365142324"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2RA6Xj87XwDo"
   },
   "outputs": [],
   "source": [
    "def convert_fer2013(data):\n",
    "    pixels = data['pixels'].tolist()\n",
    "        \n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'), (width, height))\n",
    "        face = np.stack((face,)*3, -1)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    \n",
    "    \n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "    \n",
    "    return faces, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9KXwGun3fWFC"
   },
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "    new_images = []\n",
    "    for img in images:\n",
    "        img = img / 255.0\n",
    "        new_images.append(img)\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jbauxpsDbgNU"
   },
   "outputs": [],
   "source": [
    "X, y = convert_fer2013(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1525331167346,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "NlQGkPLvACzN",
    "outputId": "6a8b0c31-1581-46d1-ce2a-c6839d7ef452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Fg5r6tkdfPH7"
   },
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D2J7d88gbjhw"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aJDceEYiyOgm"
   },
   "outputs": [],
   "source": [
    "del(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "oIJzieVCgT0j"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1522660780135,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "d_HvqERKg8MN",
    "outputId": "03e9c920-c438-40c9-b2e3-dbad1b7d02d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 23, 23, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 5,905,863\n",
      "Trainable params: 5,902,151\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zomC5FUXg96a"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cXR87YhOH-II"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./logs') \n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(MODELPATH, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3203524,
     "status": "ok",
     "timestamp": 1522663985251,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "QxDQtooDhS2K",
    "outputId": "0a292315-7c6b-4f76-a09f-8f0b3cdf14ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29068 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "29068/29068 [==============================] - 69s 2ms/step - loss: 2.0089 - acc: 0.2149 - val_loss: 1.8314 - val_acc: 0.2455\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.83139, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 2/100\n",
      " 5312/29068 [====>.........................] - ETA: 54s - loss: 1.8511 - acc: 0.234629068/29068 [==============================] - 68s 2ms/step - loss: 1.8336 - acc: 0.2447 - val_loss: 1.8686 - val_acc: 0.2455\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "16832/29068 [================>.............] - ETA: 27s - loss: 1.8172 - acc: 0.244229068/29068 [==============================] - 68s 2ms/step - loss: 1.8135 - acc: 0.2490 - val_loss: 1.8457 - val_acc: 0.2455\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "20480/29068 [====================>.........] - ETA: 19s - loss: 1.7684 - acc: 0.280029068/29068 [==============================] - 68s 2ms/step - loss: 1.7587 - acc: 0.2859 - val_loss: 1.8207 - val_acc: 0.2527\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.83139 to 1.82067, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 5/100\n",
      "16576/29068 [================>.............] - ETA: 28s - loss: 1.6764 - acc: 0.331029068/29068 [==============================] - 68s 2ms/step - loss: 1.6511 - acc: 0.3434 - val_loss: 1.5497 - val_acc: 0.3940\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.82067 to 1.54973, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 6/100\n",
      "15552/29068 [===============>..............] - ETA: 30s - loss: 1.5657 - acc: 0.382729068/29068 [==============================] - 69s 2ms/step - loss: 1.5534 - acc: 0.3873 - val_loss: 1.4305 - val_acc: 0.4218\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.54973 to 1.43053, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 7/100\n",
      "15296/29068 [==============>...............] - ETA: 31s - loss: 1.4922 - acc: 0.415829068/29068 [==============================] - 69s 2ms/step - loss: 1.4881 - acc: 0.4202 - val_loss: 1.4465 - val_acc: 0.4475\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "20032/29068 [===================>..........] - ETA: 20s - loss: 1.4379 - acc: 0.446829068/29068 [==============================] - 68s 2ms/step - loss: 1.4306 - acc: 0.4521 - val_loss: 1.5908 - val_acc: 0.3915\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "21568/29068 [=====================>........] - ETA: 17s - loss: 1.3933 - acc: 0.467229068/29068 [==============================] - 68s 2ms/step - loss: 1.3888 - acc: 0.4694 - val_loss: 1.3171 - val_acc: 0.4887\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.43053 to 1.31707, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 10/100\n",
      "16768/29068 [================>.............] - ETA: 28s - loss: 1.3445 - acc: 0.485329068/29068 [==============================] - 69s 2ms/step - loss: 1.3462 - acc: 0.4856 - val_loss: 1.3148 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.31707 to 1.31484, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 11/100\n",
      "15552/29068 [===============>..............] - ETA: 30s - loss: 1.3111 - acc: 0.496729068/29068 [==============================] - 68s 2ms/step - loss: 1.3080 - acc: 0.5004 - val_loss: 1.4186 - val_acc: 0.4542\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "20032/29068 [===================>..........] - ETA: 20s - loss: 1.2857 - acc: 0.514629068/29068 [==============================] - 69s 2ms/step - loss: 1.2825 - acc: 0.5162 - val_loss: 1.3418 - val_acc: 0.5024\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "21440/29068 [=====================>........] - ETA: 17s - loss: 1.2591 - acc: 0.530929068/29068 [==============================] - 68s 2ms/step - loss: 1.2562 - acc: 0.5316 - val_loss: 1.2475 - val_acc: 0.5277\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.31484 to 1.24752, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 14/100\n",
      "16704/29068 [================>.............] - ETA: 28s - loss: 1.2231 - acc: 0.538329068/29068 [==============================] - 69s 2ms/step - loss: 1.2253 - acc: 0.5393 - val_loss: 1.2520 - val_acc: 0.5336\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "20416/29068 [====================>.........] - ETA: 19s - loss: 1.2069 - acc: 0.547929068/29068 [==============================] - 69s 2ms/step - loss: 1.2108 - acc: 0.5481 - val_loss: 1.1852 - val_acc: 0.5450\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.24752 to 1.18520, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 16/100\n",
      "16512/29068 [================>.............] - ETA: 28s - loss: 1.1732 - acc: 0.564629068/29068 [==============================] - 69s 2ms/step - loss: 1.1806 - acc: 0.5621 - val_loss: 1.1667 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.18520 to 1.16673, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 17/100\n",
      "15552/29068 [===============>..............] - ETA: 30s - loss: 1.1450 - acc: 0.579829068/29068 [==============================] - 69s 2ms/step - loss: 1.1554 - acc: 0.5770 - val_loss: 1.1491 - val_acc: 0.5662\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.16673 to 1.14915, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 18/100\n",
      "15296/29068 [==============>...............] - ETA: 31s - loss: 1.1387 - acc: 0.580829068/29068 [==============================] - 69s 2ms/step - loss: 1.1363 - acc: 0.5815 - val_loss: 1.1735 - val_acc: 0.5542\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "19968/29068 [===================>..........] - ETA: 20s - loss: 1.1151 - acc: 0.589129068/29068 [==============================] - 68s 2ms/step - loss: 1.1175 - acc: 0.5890 - val_loss: 1.1018 - val_acc: 0.5918\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.14915 to 1.10175, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 20/100\n",
      "16384/29068 [===============>..............] - ETA: 29s - loss: 1.0847 - acc: 0.603129068/29068 [==============================] - 69s 2ms/step - loss: 1.0960 - acc: 0.5995 - val_loss: 1.1453 - val_acc: 0.5734\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "20288/29068 [===================>..........] - ETA: 19s - loss: 1.0699 - acc: 0.607529068/29068 [==============================] - 68s 2ms/step - loss: 1.0744 - acc: 0.6080 - val_loss: 1.1264 - val_acc: 0.5954\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "21568/29068 [=====================>........] - ETA: 17s - loss: 1.0524 - acc: 0.616729068/29068 [==============================] - 68s 2ms/step - loss: 1.0563 - acc: 0.6161 - val_loss: 1.1070 - val_acc: 0.5899\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "21952/29068 [=====================>........] - ETA: 16s - loss: 1.0379 - acc: 0.630629068/29068 [==============================] - 68s 2ms/step - loss: 1.0396 - acc: 0.6285 - val_loss: 1.1663 - val_acc: 0.5784\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "16832/29068 [================>.............] - ETA: 27s - loss: 0.9888 - acc: 0.642729068/29068 [==============================] - 69s 2ms/step - loss: 1.0039 - acc: 0.6366 - val_loss: 1.1600 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "20416/29068 [====================>.........] - ETA: 19s - loss: 0.9699 - acc: 0.647529068/29068 [==============================] - 69s 2ms/step - loss: 0.9775 - acc: 0.6439 - val_loss: 1.0835 - val_acc: 0.6049\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.10175 to 1.08348, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 26/100\n",
      "16512/29068 [================>.............] - ETA: 28s - loss: 0.9569 - acc: 0.652029068/29068 [==============================] - 69s 2ms/step - loss: 0.9616 - acc: 0.6492 - val_loss: 1.0777 - val_acc: 0.6105\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.08348 to 1.07774, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 27/100\n",
      "15488/29068 [==============>...............] - ETA: 30s - loss: 0.9368 - acc: 0.659929068/29068 [==============================] - 69s 2ms/step - loss: 0.9377 - acc: 0.6604 - val_loss: 1.0855 - val_acc: 0.6052\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20032/29068 [===================>..........] - ETA: 20s - loss: 0.9183 - acc: 0.668529068/29068 [==============================] - 68s 2ms/step - loss: 0.9199 - acc: 0.6693 - val_loss: 1.0598 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.07774 to 1.05978, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 29/100\n",
      "16384/29068 [===============>..............] - ETA: 28s - loss: 0.9085 - acc: 0.670329068/29068 [==============================] - 68s 2ms/step - loss: 0.9094 - acc: 0.6704 - val_loss: 1.1261 - val_acc: 0.5921\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      "20288/29068 [===================>..........] - ETA: 19s - loss: 0.8831 - acc: 0.685129068/29068 [==============================] - 68s 2ms/step - loss: 0.8923 - acc: 0.6816 - val_loss: 1.0810 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "21568/29068 [=====================>........] - ETA: 17s - loss: 0.8714 - acc: 0.686929068/29068 [==============================] - 68s 2ms/step - loss: 0.8687 - acc: 0.6871 - val_loss: 1.1202 - val_acc: 0.6211\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "21952/29068 [=====================>........] - ETA: 16s - loss: 0.8485 - acc: 0.695329068/29068 [==============================] - 68s 2ms/step - loss: 0.8552 - acc: 0.6927 - val_loss: 1.0935 - val_acc: 0.6121\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "16832/29068 [================>.............] - ETA: 27s - loss: 0.8224 - acc: 0.701729068/29068 [==============================] - 68s 2ms/step - loss: 0.8300 - acc: 0.7023 - val_loss: 1.0575 - val_acc: 0.6227\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.05978 to 1.05752, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 34/100\n",
      "15616/29068 [===============>..............] - ETA: 30s - loss: 0.8013 - acc: 0.710629068/29068 [==============================] - 69s 2ms/step - loss: 0.8061 - acc: 0.7085 - val_loss: 1.0907 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "20032/29068 [===================>..........] - ETA: 20s - loss: 0.7837 - acc: 0.715729068/29068 [==============================] - 68s 2ms/step - loss: 0.7865 - acc: 0.7157 - val_loss: 1.0491 - val_acc: 0.6383\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.05752 to 1.04909, saving model to drive/Emotion Recognition/models/model_v5.h5\n",
      "Epoch 36/100\n",
      "16384/29068 [===============>..............] - ETA: 28s - loss: 0.7559 - acc: 0.728529068/29068 [==============================] - 69s 2ms/step - loss: 0.7655 - acc: 0.7234 - val_loss: 1.1081 - val_acc: 0.6177\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "20288/29068 [===================>..........] - ETA: 19s - loss: 0.7702 - acc: 0.726029068/29068 [==============================] - 69s 2ms/step - loss: 0.7669 - acc: 0.7259 - val_loss: 1.0920 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "21568/29068 [=====================>........] - ETA: 17s - loss: 0.7370 - acc: 0.734429068/29068 [==============================] - 69s 2ms/step - loss: 0.7394 - acc: 0.7345 - val_loss: 1.0872 - val_acc: 0.6395\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "21952/29068 [=====================>........] - ETA: 16s - loss: 0.7188 - acc: 0.741429068/29068 [==============================] - 68s 2ms/step - loss: 0.7192 - acc: 0.7431 - val_loss: 1.1940 - val_acc: 0.6239\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "16832/29068 [================>.............] - ETA: 27s - loss: 0.6862 - acc: 0.754629068/29068 [==============================] - 68s 2ms/step - loss: 0.6964 - acc: 0.7513 - val_loss: 1.1062 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "20416/29068 [====================>.........] - ETA: 19s - loss: 0.6877 - acc: 0.755929068/29068 [==============================] - 69s 2ms/step - loss: 0.6869 - acc: 0.7565 - val_loss: 1.1320 - val_acc: 0.6230\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "21568/29068 [=====================>........] - ETA: 17s - loss: 0.6704 - acc: 0.763429068/29068 [==============================] - 68s 2ms/step - loss: 0.6696 - acc: 0.7629 - val_loss: 1.0787 - val_acc: 0.6417\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "16768/29068 [================>.............] - ETA: 27s - loss: 0.6375 - acc: 0.774829068/29068 [==============================] - 68s 2ms/step - loss: 0.6468 - acc: 0.7704 - val_loss: 1.0771 - val_acc: 0.6411\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 00043: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f032de79240>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)),\n",
    "          shuffle=True,\n",
    "          callbacks=[reduce_lr, tensorboard, early_stopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3131,
     "status": "ok",
     "timestamp": 1522664002098,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "eR1zpzh1hbfk",
    "outputId": "dc6519e3-60ca-4e2b-dd97-4529fae0cdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 2s 686us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(np.array(X_test), np.array(y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1522664004048,
     "user": {
      "displayName": "Furkan Kınlı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115474757520612475230"
     },
     "user_tz": -180
    },
    "id": "6AeWepyU4pgl",
    "outputId": "cff02b6f-4093-4445-bd57-8691a7d9640c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0770609875215598\n",
      "Accuracy: 0.6411256617608261\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "J2igFGJW4sZ2"
   },
   "outputs": [],
   "source": [
    "model.save(MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0KOGhD_P49ut"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "emotion_recognition.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
